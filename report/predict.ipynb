{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/home/rafatmatting/anaconda3/envs/ml/bin/python\n",
    "import torch\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from networks.UNet import UNet\n",
    "from networks.MODNet import MODNet\n",
    "from networks.GFM import GFM\n",
    "from networks.DFM import DFM\n",
    "from datasets.MattingDataModule import MattingDataModule\n",
    "from pytorch_lightning.callbacks import (\n",
    "    ModelCheckpoint,\n",
    "    ModelSummary,\n",
    "    LearningRateMonitor,\n",
    ")\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "\n",
    "model_type = \"GFM\"\n",
    "dataset_name = \"test\"\n",
    "dataset_config = \"config/datasets.yaml\"\n",
    "epochs = 60\n",
    "num_workers = 32\n",
    "batch_size = 1\n",
    "resume_from_checkpoint  = \"\"\n",
    "learning_rate = .01\n",
    "log_folder = \"./logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_transform(height: int = 224, width: int = 224):\n",
    "    return A.Compose(\n",
    "        [\n",
    "            # A.RandomCrop(height=height,width=width),\n",
    "            A.Resize(width=height, height=width),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        additional_targets={\n",
    "            \"image\": \"image\",\n",
    "            \"mask\": \"image\",\n",
    "            \"trimap\": \"image\",\n",
    "            \"fg\": \"image\",\n",
    "            \"bg\": \"image\",\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "        \"learning_rate\": 1,\n",
    "        \"monitor\": \"validation_loss\"\n",
    "    }\n",
    "\n",
    "if model_type == \"MODNet\":\n",
    "    network = MODNet(settings)\n",
    "elif model_type == \"UNet\":\n",
    "    network = UNet(settings)\n",
    "elif model_type == \"GFM\":\n",
    "    network = GFM(settings)\n",
    "elif model_type == \"DFM\":\n",
    "    network = DFM(settings)\n",
    "else:\n",
    "    raise Exception(\"model_type not given\")\n",
    "\n",
    "\"\"\"_dataset_\n",
    "\"\"\"\n",
    "data_module = MattingDataModule(dataset_name=dataset_name, num_workers=num_workers, batch_size=batch_size, transform=create_test_transform())\n",
    "\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "experiment_name = f\"{model_type}_{dataset_name}\"\n",
    "version_name = f\"epochs:{epochs}_lr:{learning_rate}\"\n",
    "tensorboard_logger = TensorBoardLogger(log_folder, name=experiment_name)\n",
    "wandb_logger = WandbLogger(project=experiment_name)\n",
    "\n",
    "checkpoint_path = os.path.join(log_folder, experiment_name, version_name, \"checkpoints\")\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        dirpath=checkpoint_path,\n",
    "        every_n_epochs=1,\n",
    "        mode=\"min\",\n",
    "        monitor=\"validation_loss\",\n",
    "        save_last=True,\n",
    "    ),\n",
    "]\n",
    "\n",
    "checkpoint_file = os.path.join(checkpoint_path,\"last.ckpt\")\n",
    "checkpoint_file = \"/home/rafatmatting/dfm/logs/GFM_AMD/resize/checkpoints/epoch=100-step=403.ckpt\"\n",
    "\n",
    "from pytorch_lightning.plugins import DDPPlugin\n",
    "trainer = Trainer(\n",
    "    logger=tensorboard_logger,\n",
    "    gpus=1,#torch.cuda.device_count(),\n",
    "    # devices=torch.cuda.device_count(),\n",
    "    # accelerator=\"gpu\",\n",
    "    # strategy=DDPPlugin(find_unused_parameters=False),\n",
    "    # strategy=DDPPlugin(),\n",
    "    callbacks=callbacks,\n",
    "    max_epochs=epochs,\n",
    "    # auto_lr_find=True,\n",
    "    # auto_scale_batch_size=True,\n",
    "    # overfit_batches=10,\n",
    "    # fast_dev_run=1,\n",
    "    # resume_from_checkpoint=checkpoint_file,\n",
    ")\n",
    "\n",
    "# trainer.tune(network, datamodule=data_module)\n",
    "predict = trainer.predict(network, dataloaders=data_module.test_dataloader(), ckpt_path=checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse = torch.Tensor([loss[1] for loss in predict]).mean()\n",
    "# mae = torch.Tensor([loss[0] for loss in predict]).mean()\n",
    "# inference = torch.Tensor([loss[2] for loss in predict]).mean()\n",
    "# images = torch.Tensor([loss[3][0] for loss in predict])\n",
    "# preds = torch.Tensor([loss[4][0] for loss in predict])\n",
    "# masks = torch.Tensor([loss[5][0] for loss in predict])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(predict[9][3].squeeze().permute(1,2,0)/255)\n",
    "plt.imshow(torch.sigmoid(predict[9][4]).squeeze()/255, cmap=\"gray\")\n",
    "plt.imshow(predict[22][4].squeeze()/255, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in enumerate(predict):\n",
    "    torchvision.utils.save_image(predict[i][3].squeeze()/255, f\"{model_type}_output/{i}_image.jpg\")\n",
    "    torchvision.utils.save_image(predict[i][4].squeeze(), f\"{model_type}_output/{i}_predict.jpg\")\n",
    "    torchvision.utils.save_image(predict[i][5].squeeze()/255, f\"{model_type}_output/{i}_mask.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = torchvision.utils.make_grid(predict[0][3].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ceaca082080308df9c13ab2e9e4facb5ed206e6e4337951b30308728357ac125"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
